# -*- coding: utf-8 -*-
import yfinance as yf
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import os
import json
from config import YF_TIMEOUT, OUTPUT_DIR, SECTOR_ETFS, INDICES

import warnings
warnings.filterwarnings('ignore', category=FutureWarning, module='yfinance')


class DataFetcher:
    def __init__(self, logger_callback):
        """
        æ•°æ®è·å–å™¨
        :param logger_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        self.logger = logger_callback
        self.cache_dir = os.path.join(OUTPUT_DIR, 'data_cache')
        os.makedirs(self.cache_dir, exist_ok=True)
        self.cache_validity = 24 * 3600  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        self.all_data = None  # å­˜å‚¨æ‰€æœ‰æ•°æ®çš„å­—å…¸
        self.cache_meta_file = os.path.join(self.cache_dir, 'cache_meta.json')
    
    def _is_cache_valid(self):
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if os.path.exists(self.cache_meta_file):
            try:
                with open(self.cache_meta_file, 'r') as f:
                    meta = json.load(f)
                cache_time = meta.get('cache_time', 0)
                current_time = datetime.now().timestamp()
                return current_time - cache_time < self.cache_validity
            except:
                pass
        return False
    
    def _load_cache(self):
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        if self._is_cache_valid():
            try:
                data_file = os.path.join(self.cache_dir, 'all_data.pkl')
                if os.path.exists(data_file):
                    self.all_data = pd.read_pickle(data_file)
                    self.logger('æ•°æ®ç¼“å­˜', 'success', 'å·²åŠ è½½ç¼“å­˜æ•°æ®')
                    return True
            except Exception as e:
                self.logger('æ•°æ®ç¼“å­˜', 'error', f'åŠ è½½ç¼“å­˜å¤±è´¥: {e}')
        return False
    
    def _save_cache(self):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            if self.all_data is not None:
                # ä¿å­˜æ•°æ®
                data_file = os.path.join(self.cache_dir, 'all_data.pkl')
                pd.to_pickle(self.all_data, data_file)
                
                # ä¿å­˜å…ƒæ•°æ®
                meta = {
                    'cache_time': datetime.now().timestamp(),
                    'data_types': list(self.all_data.keys()),
                    'last_update': datetime.now().isoformat()
                }
                with open(self.cache_meta_file, 'w') as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)
                
                self.logger('æ•°æ®ç¼“å­˜', 'success', 'å·²ä¿å­˜æ•°æ®åˆ°ç¼“å­˜')
        except Exception as e:
            self.logger('æ•°æ®ç¼“å­˜', 'error', f'ä¿å­˜ç¼“å­˜å¤±è´¥: {e}')
    def get_yf_data(self, ticker, period="3mo", interval='1d'):
        """
        è·å–yfinanceæ•°æ®
        :param ticker: è‚¡ç¥¨ä»£ç 
        :param period: å‘¨æœŸ
        :param interval: é—´éš”
        :return: DataFrame with columns: [Open, High, Low, Close, Volume]
        """
        try:
            data = yf.download(
                ticker, period=period, interval=interval, auto_adjust=True, 
                progress=False, timeout=YF_TIMEOUT
            )
            
            if data.empty:
                self.logger('YFinance', 'warning', f'{ticker} è¿”å›ç©ºæ•°æ®')
                return pd.DataFrame()
            
            # å¤„ç†å¤šåˆ—æƒ…å†µ - æ‰å¹³åŒ–åˆ—ç´¢å¼•
            if isinstance(data.columns, pd.MultiIndex):
                # å•ä¸ª ticker æ—¶ï¼Œyfinance è¿”å›çš„ MultiIndex æœ‰ ticker å±‚
                data.columns = data.columns.droplevel(1)
            
            # ç¡®ä¿è¿”å›çš„ DataFrame æœ‰æ­£ç¡®çš„åˆ—å
            expected_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            if not all(col in data.columns for col in expected_cols):
                # å¦‚æœåªæœ‰ Close åˆ—ï¼ˆæŸäº›æŒ‡æ•°æ•°æ®ï¼‰
                if len(data.columns) == 1:
                    data.columns = ['Close']
            
            return data
            
        except Exception as e:
            self.logger('YFinance', 'error', f'{ticker}: {str(e)}')
            return pd.DataFrame()


    def fetch_all_data(self, force_refresh=False):
        """ä¸€æ¬¡æ€§è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®"""
        if not force_refresh and self._load_cache():
            return
        
        self.logger('æ•°æ®è·å–', 'info', 'å¼€å§‹è·å–æ‰€æœ‰æ•°æ®...')
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365*3)  # è·å–3å¹´æ•°æ®
        start_date_str = start_date.strftime('%Y%m%d')
        end_date_str = end_date.strftime('%Y%m%d')
        
        self.all_data = {}
        
        # 1. èèµ„ä½™é¢
        self.logger('æ•°æ®è·å–', 'info', 'è·å–èèµ„ä½™é¢æ•°æ®...')
        try:
            data = ak.stock_margin_sse(start_date=start_date_str, end_date=end_date_str)
            if not data.empty and len(data.columns) >= 2:
                data = data.iloc[:, [0, 1]].iloc[::-1]
                data['ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(data['ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ'], errors='coerce', format='%Y%m%d')
                # ç»Ÿä¸€é•¿åº¦ä¸º300
                series_data = data.dropna().set_index('ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ')['èèµ„ä½™é¢'].iloc[-300:]
                self.all_data['èèµ„ä½™é¢'] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âœ… èèµ„ä½™é¢: {len(series_data)} æ¡è®°å½•")
            else:
                self.all_data['èèµ„ä½™é¢'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âš ï¸  èèµ„ä½™é¢: ç©ºæ•°æ®")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'èèµ„ä½™é¢: {str(e)[:100]}')
            self.all_data['èèµ„ä½™é¢'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ èèµ„ä½™é¢: è·å–å¤±è´¥ - {str(e)[:50]}")
        
        
        
        # 3. Shibor 1M
        self.logger('æ•°æ®è·å–', 'info', 'è·å–Shiboræ•°æ®...')
        try:
            data = ak.macro_china_shibor_all()
            if not data.empty and 'æ—¥æœŸ' in data.columns and '1M-å®šä»·' in data.columns:
                data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'], errors='coerce', format='%Y%m%d')
                # ç»Ÿä¸€é•¿åº¦ä¸º300
                series_data = data.dropna().set_index('æ—¥æœŸ')['1M-å®šä»·'].iloc[-300:]
                self.all_data['Shibor 1M'] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âœ… Shibor 1M: {len(series_data)} æ¡è®°å½•")
            else:
                self.all_data['Shibor 1M'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âš ï¸  Shibor 1M: ç©ºæ•°æ®")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'Shibor: {str(e)[:100]}')
            self.all_data['Shibor 1M'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ Shibor 1M: è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 4. ä¸­ç¾å›½å€ºæ”¶ç›Šç‡åŠç›¸å…³æ•°æ®
        self.logger('æ•°æ®è·å–', 'info', 'è·å–ä¸­ç¾å›½å€ºæ”¶ç›Šç‡æ•°æ®...')
        try:
            data = ak.bond_zh_us_rate()[['æ—¥æœŸ','ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´', 'ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´']].iloc[-600:]
            data['spread'] = data['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'] - data['ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´']
            data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'], errors='coerce', format='%Y%m%d')
            data = data.set_index('æ—¥æœŸ')
            data = data.ffill(axis=0)
            # ç»Ÿä¸€é•¿åº¦ä¸º300
            self.all_data['ä¸­ç¾å›½å€ºæ”¶ç›Šç‡'] = pd.DataFrame({'value': data['spread'].iloc[-300:]}) if not data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            # ä¿å­˜ç¾å›½å›½å€ºæ”¶ç›Šç‡
            self.all_data['US_BOND'] = pd.DataFrame({'value': data['ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´'].iloc[-300:]}) if not data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            # ä¿å­˜ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´
            self.all_data['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'] = pd.DataFrame({'value': data['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'].iloc[-300:]}) if not data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âœ… ä¸­ç¾å›½å€ºæ”¶ç›Šç‡: {len(data.iloc[-300:])} æ¡è®°å½•")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'ä¸­ç¾å›½å€ºæ”¶ç›Šç‡: {str(e)[:100]}')
            self.all_data['ä¸­ç¾å›½å€ºæ”¶ç›Šç‡'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            self.all_data['US_BOND'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            self.all_data['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ ä¸­ç¾å›½å€ºæ”¶ç›Šç‡: è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 5. ETFæ•°æ®
        etf_list = {'ETF_510300': '510300', 'ETF_159845': '159845', 'ETF_510500': '510500'}
        for etf_key, etf_code in etf_list.items():
            self.logger('æ•°æ®è·å–', 'info', f'è·å–{etf_key}æ•°æ®...')
            try:
                data = ak.fund_etf_hist_em(symbol=etf_code)
                if not data.empty and 'æ—¥æœŸ' in data.columns and 'æ”¶ç›˜' in data.columns:
                    data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'], errors='coerce')
                    # ç»Ÿä¸€é•¿åº¦ä¸º300
                    series_data = data.dropna().set_index('æ—¥æœŸ')['æ”¶ç›˜'].iloc[-300:]
                    self.all_data[etf_key] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                    print(f"  âœ… {etf_key}: {len(series_data)} æ¡è®°å½•")
                else:
                    self.all_data[etf_key] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                    print(f"  âš ï¸  {etf_key}: ç©ºæ•°æ®")
            except Exception as e:
                self.logger('æ•°æ®è·å–', 'warning', f'{etf_key}: {str(e)[:100]}')
                self.all_data[etf_key] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âŒ {etf_key}: è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 6. åŸæ²¹ä»·æ ¼
        self.logger('æ•°æ®è·å–', 'info', 'è·å–åŸæ²¹ä»·æ ¼æ•°æ®...')
        try:
            data = ak.futures_foreign_hist(symbol='CL')
            if not data.empty and 'date' in data.columns and 'close' in data.columns:
                data_copy = data.copy()
                data_copy['date'] = pd.to_datetime(data_copy['date'], errors='coerce')
                # ç»Ÿä¸€é•¿åº¦ä¸º300
                series_data = data_copy.dropna().sort_values('date').set_index('date')['close'].iloc[-300:]
                self.all_data['CL'] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âœ… åŸæ²¹ä»·æ ¼(CL): {len(series_data)} æ¡è®°å½•")
            else:
                self.all_data['CL'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âš ï¸  åŸæ²¹ä»·æ ¼(CL): ç©ºæ•°æ®")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'åŸæ²¹ä»·æ ¼: {str(e)[:100]}')
            self.all_data['CL'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ åŸæ²¹ä»·æ ¼(CL): è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 7. é»„é‡‘ä»·æ ¼
        self.logger('æ•°æ®è·å–', 'info', 'è·å–é»„é‡‘ä»·æ ¼æ•°æ®...')
        try:
            data = ak.futures_foreign_hist(symbol='GC')
            if not data.empty and 'date' in data.columns and 'close' in data.columns:
                data_copy = data.copy()
                data_copy['date'] = pd.to_datetime(data_copy['date'], errors='coerce')
                # ç»Ÿä¸€é•¿åº¦ä¸º300
                series_data = data_copy.dropna().sort_values('date').set_index('date')['close'].iloc[-300:]
                self.all_data['GC'] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âœ… é»„é‡‘ä»·æ ¼(GC): {len(series_data)} æ¡è®°å½•")
            else:
                self.all_data['GC'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
                print(f"  âš ï¸  é»„é‡‘ä»·æ ¼(GC): ç©ºæ•°æ®")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'é»„é‡‘ä»·æ ¼: {str(e)[:100]}')
            self.all_data['GC'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ é»„é‡‘ä»·æ ¼(GC): è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 8. è‚¡å€ºåˆ©å·®ç›¸å…³æ•°æ®
        self.logger('æ•°æ®è·å–', 'info', 'è·å–è‚¡å€ºåˆ©å·®ç›¸å…³æ•°æ®...')
        # ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡
        try:
            pe_df = ak.stock_index_pe_lg(symbol="ä¸Šè¯50")[['æ—¥æœŸ','æ»šåŠ¨å¸‚ç›ˆç‡']]
            pe_df['æ—¥æœŸ'] = pd.to_datetime(pe_df['æ—¥æœŸ'], errors='coerce')
            pe_df.set_index('æ—¥æœŸ', inplace=True)
            # ç»Ÿä¸€é•¿åº¦ä¸º300
            series_data = pe_df['æ»šåŠ¨å¸‚ç›ˆç‡'].iloc[-300:]
            self.all_data['ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡'] = pd.DataFrame({'value': series_data}) if not series_data.empty else pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âœ… ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡: {len(series_data)} æ¡è®°å½•")
        except Exception as e:
            self.logger('æ•°æ®è·å–', 'warning', f'ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡: {str(e)[:100]}')
            self.all_data['ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡'] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['value'])
            print(f"  âŒ ä¸Šè¯50æ»šåŠ¨å¸‚ç›ˆç‡: è·å–å¤±è´¥ - {str(e)[:50]}")
        
        # 10. Yfæ•°æ® - è¡¥å……æ›´å¤šå…¨çƒæŒ‡æ•°å’ŒETF
        # INDICESæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯(ä»£ç , æ–‡ä»¶å, [å‘¨æœŸ])ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºä»£ç 
        indices = [idx[0] for idx in INDICES]
        #SECTOR_ETFSæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯(ä»£ç , æ–‡ä»¶å)ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºä»£ç 
        sector_tickers = list(SECTOR_ETFS.values())

        self.logger('æ•°æ®è·å–', 'info', 'è·å–æŒ‡æ•°æ•°æ®...')
        success_count = 0
        for idx in indices+sector_tickers:
            if idx not in self.all_data:
                try:
                    idx_data = self.get_yf_data(idx, period="300d")
                    if not idx_data.empty:
                        self.all_data[idx] = idx_data  # ä¿å­˜å®Œæ•´OHLCæ•°æ®
                        print(f"  âœ… {idx}: {idx_data.shape} è®°å½•")
                        success_count += 1
                    else:
                        # è¿”å›å¸¦OHLCåˆ—çš„ç©ºDataFrame
                        self.all_data[idx] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['Open', 'High', 'Low', 'Close', 'Volume'])
                        print(f"  âš ï¸  {idx}: ç©ºæ•°æ®")
                except Exception as e:
                    self.logger('æ•°æ®è·å–', 'warning', f'{idx}: {str(e)[:100]}')
                    # è¿”å›å¸¦OHLCåˆ—çš„ç©ºDataFrame
                    self.all_data[idx] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['Open', 'High', 'Low', 'Close', 'Volume'])
                    print(f"  âŒ {idx}: è·å–å¤±è´¥ - {str(e)[:50]}")
        print(f"  ğŸ“Š æŒ‡æ•°æ•°æ®è·å–å®Œæˆ: {success_count}/{len(indices+sector_tickers)} æˆåŠŸ")
        
        self.logger('æ•°æ®è·å–', 'success', f'å·²è·å–æ‰€æœ‰æ•°æ®ï¼Œå…±{len(self.all_data)}ç§æ•°æ®ç±»å‹')
        
        # æ‰“å°è¯¦ç»†æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'-'*100}")
        print(f"{'æ•°æ®ç±»å‹':<25} {'æ ¼å¼':<10} {'Shape':<15} {'çŠ¶æ€':<10} {'æœ€æ–°æ—¥æœŸ':<15}")
        print(f"{'-'*100}")
        
        total_records = 0
        valid_data_count = 0
        
        for key, data in self.all_data.items():
            if isinstance(data, pd.DataFrame):
                row_count, col_count = data.shape
                data_format = "DataFrame"
                status = "æ­£å¸¸" if row_count > 0 else "ç©º"
                # è·å–æœ€æ–°æ—¥æœŸ
                if row_count > 0 and isinstance(data.index, pd.DatetimeIndex):
                    latest_date = data.index[-1].strftime('%Y-%m-%d')
                else:
                    latest_date = "N/A"
                print(f"{key:<25} {data_format:<10} {(row_count, col_count):<15} {status:<10} {latest_date:<15}")
                total_records += row_count
                if row_count > 0:
                    valid_data_count += 1
            else:
                print(f"{key:<25} {'å¼‚å¸¸':<10} {'-':<15} {'å¼‚å¸¸':<10} {'-':<15}")
        
        print(f"{'-'*100}")
        print(f"ç»Ÿè®¡æ‘˜è¦: å…±{len(self.all_data)}ç§æ•°æ®ç±»å‹ï¼Œ{valid_data_count}ç§æœ‰æ•ˆæ•°æ®ï¼Œæ€»è®°å½•æ•°{total_records}")
        print(f"æ•°æ®ç¼“å­˜è·¯å¾„: {os.path.abspath(self.cache_dir)}")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_cache()
    
    def get_cached_data(self, symbol):
        """ä»ç¼“å­˜è·å–æ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨åˆ™è·å–"""
        if self.all_data is None:
            self.fetch_all_data()
        
        if symbol in self.all_data:
            return self.all_data[symbol]
        else:
            # å¦‚æœæ•°æ®ä¸åœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•ä»yfinanceè·å–
            self.logger('æ•°æ®è·å–', 'info', f'ç¼“å­˜ä¸­æœªæ‰¾åˆ°{symbol}ï¼Œå°è¯•ä»yfinanceè·å–...')
            idx_data = self.get_yf_data(symbol, period="300d")
            if not idx_data.empty:
                self.all_data[symbol] = idx_data  # ä¿å­˜å®Œæ•´OHLCæ•°æ®
            else:
                # è¿”å›å¸¦OHLCåˆ—çš„ç©ºDataFrame
                self.all_data[symbol] = pd.DataFrame(index=pd.DatetimeIndex([]), columns=['Open', 'High', 'Low', 'Close', 'Volume'])
            return self.all_data[symbol]
    
    
    
    
